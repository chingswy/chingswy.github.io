<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>multi-view | Qing Shuai | 帅青</title> <meta name="author" content="Qing Shuai"/> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="chingswy.github.io/tags/multi-view/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Qing Shuai | 帅青</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <i class="fas fa-hashtag fa-sm"></i> multi-view </h1> <p class="post-description"> Papers with tag multi-view </p> </header> <div class="publications"> <h2 class="year">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-3 abbr"></div> <div id="2210.10771" class="col-sm-8"> <div class="title">Multi-view Tracking Using Weakly Supervised Human Motion Prediction</div> <div class="author"> Martin Engilberge, Weizhe Liu, and <a href="https://people.epfl.ch/pascal.fua/bio?lang=en" target="_blank" rel="noopener noreferrer">Pascal Fua</a> </div> <div class="periodical"> <em>In </em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2210.10771.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> </div> <div class="abstract hidden"> <p>Multi-view approaches to people-tracking have the potential to better handleocclusions than single-view ones in crowded scenes. They often rely on thetracking-by-detection paradigm, which involves detecting people first and thenconnecting the detections. In this paper, we argue that an even more effectiveapproach is to predict people motion over time and infer people’s presence inindividual frames from these. This enables to enforce consistency both overtime and across views of a single temporal frame. We validate our approach onthe PETS2009 and WILDTRACK datasets and demonstrate that it outperformsstate-of-the-art methods.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">2210.10771</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multi-view Tracking Using Weakly Supervised Human Motion Prediction}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Engilberge, Martin and Liu, Weizhe and Fua, Pascal}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">tags</span> <span class="p">=</span> <span class="s">{multi-view, tracking, motion}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> <a href="/tags/multi-view"> <i class="fas fa-hashtag fa-sm"></i> multi-view</a>  <a href="/tags/tracking"> <i class="fas fa-hashtag fa-sm"></i> tracking</a>  <a href="/tags/motion"> <i class="fas fa-hashtag fa-sm"></i> motion</a>  </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 abbr"></div> <div id="2210.01886" class="col-sm-8"> <div class="title">Multi-view Human Body Mesh Translator</div> <div class="author"> Xiangjian Jiang, Xuecheng Nie, Zitian Wang, Luoqi Liu, and Si Liu</div> <div class="periodical"> <em>In </em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/pdf/2210.01886.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> </div> <div class="abstract hidden"> <p>Existing methods for human mesh recovery mainly focus on single-viewframeworks, but they often fail to produce accurate results due to theill-posed setup. Considering the maturity of the multi-view motion capturesystem, in this paper, we propose to solve the prior ill-posed problem byleveraging multiple images from different views, thus significantly enhancingthe quality of recovered meshes. In particular, we present a novel\textbfMulti-view human body \textbfMesh \textbfTranslator (MMT) modelfor estimating human body mesh with the help of vision transformer.Specifically, MMT takes multi-view images as input and translates them totargeted meshes in a single-forward manner. MMT fuses features of differentviews in both encoding and decoding phases, leading to representations embeddedwith global information. Additionally, to ensure the tokens are intensivelyfocused on the human pose and shape, MMT conducts cross-view alignment at thefeature level by projecting 3D keypoint positions to each view and enforcingtheir consistency in geometry constraints. Comprehensive experimentsdemonstrate that MMT outperforms existing single or multi-view models by alarge margin for human mesh recovery task, notably, 28.8% improvement in MPVEover the current state-of-the-art method on the challenging HUMBI dataset.Qualitative evaluation also verifies the effectiveness of MMT in reconstructinghigh-quality human mesh. Codes will be made available upon acceptance.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">2210.01886</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multi-view Human Body Mesh Translator}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Jiang, Xiangjian and Nie, Xuecheng and Wang, Zitian and Liu, Luoqi and Liu, Si}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">tags</span> <span class="p">=</span> <span class="s">{multi-view, SMPL, transformer}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> <a href="/tags/multi-view"> <i class="fas fa-hashtag fa-sm"></i> multi-view</a>  <a href="/tags/smpl"> <i class="fas fa-hashtag fa-sm"></i> SMPL</a>  <a href="/tags/transformer"> <i class="fas fa-hashtag fa-sm"></i> transformer</a>  </div> </div> </li> </ol> <ol class="bibliography"></ol> <h2 class="year">2021</h2> <ol class="bibliography"></ol> <ol class="bibliography"></ol> <h2 class="year">2020</h2> <ol class="bibliography"></ol> <ol class="bibliography"></ol> <h2 class="year">2019</h2> <ol class="bibliography"></ol> <ol class="bibliography"></ol> <h2 class="year">2018</h2> <ol class="bibliography"></ol> <ol class="bibliography"></ol> <h2 class="year">2017</h2> <ol class="bibliography"></ol> <ol class="bibliography"></ol> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Qing Shuai. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </div></body> </html>